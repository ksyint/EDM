==> command line args: 
{'use_cpu': False, 'gradient_accumulate_step': 1, 'split_batches': False, 'mixed_precision': False, 'init_scale': 65536.0, 'growth_factor': 2.0, 'backoff_factor': 0.5, 'growth_interval': 2000, 'max_grad_norm': -1, 'use_wandb': False, 'project_name': 'SketchGeneration', 'entity': 'ximinng', 'tensorboard': False, 'seed': 8019, 'results_path': './workdir/medical', 'log_step': 1000, 'eval_step': 10, 'save_step': 10, 'update': '', 'split': 'test', 'num_workers': 6, 'shuffle': False, 'drop_last': False, 'task': 'diffsketcher', 'num_outputs': 4, 'model_id': 'medsd', 'config': 'diffsketcher.yaml', 'style_file': None, 'prompt': 'A brain PET-MRI axial image with huge tumors', 'negative_prompt': None, 'print_timing': False, 'download': True, 'force_download': False, 'resume_download': False, 'render_batch': False, 'seed_range': 'None', 'make_video': False, 'video_frame_freq': 1, 'video_frame_rate': 36, 'token_ind': 4, 'num_paths': 1200, 'num_iter': 500}
==> yaml config args: 
{'image_size': 224, 'path_svg': None, 'mask_object': False, 'fix_scale': False, 'num_iter': 500, 'batch_size': 1, 'num_stages': 1, 'lr_scheduler': False, 'lr_decay_rate': 0.1, 'decay_steps': [1000, 1500], 'lr': 1, 'color_lr': 0.01, 'pruning_freq': 50, 'color_vars_threshold': 0.1, 'width_lr': 0.1, 'max_width': 50, 'num_paths': 1200, 'width': 1.5, 'control_points_per_seg': 4, 'num_segments': 1, 'optim_opacity': True, 'optim_width': False, 'optim_rgba': False, 'opacity_delta': 0, 'attention_init': True, 'xdog_intersec': True, 'softmax_temp': 0.5, 'cross_attn_res': 16, 'self_attn_res': 32, 'max_com': 20, 'mean_comp': False, 'comp_idx': 0, 'attn_coeff': 1.0, 'log_cross_attn': False, 'u2net_path': './checkpoint/u2net/u2net.pth', 'model_id': 'sd15', 'ldm_speed_up': False, 'enable_xformers': True, 'gradient_checkpoint': False, 'token_ind': 4, 'use_ddim': True, 'num_inference_steps': 100, 'guidance_scale': 7.5, 'sds': {'crop_size': 512, 'augmentations': 'affine', 'guidance_scale': 100, 'grad_scale': 1e-06, 't_range': [0.05, 0.95], 'warmup': 2000}, 'clip': {'model_name': 'RN101', 'feats_loss_type': 'l2', 'feats_loss_weights': [0, 0, 1.0, 1.0, 0], 'fc_loss_weight': 0.1, 'augmentations': 'affine', 'num_aug': 4, 'vis_loss': 1, 'text_visual_coeff': 0}, 'perceptual': {'name': 'lpips', 'lpips_net': 'vgg', 'coeff': 0.2}}

***** Model State *****
-> Mixed Precision: no, AMP: False, Gradient Accumulate Step: 1
-> Weight dtype:  torch.float32
-> Working Space: '/home/hbc/DS/DiffSketcher/diffsketcher/sd8019-im224-P1200W1.5OP-tk4-XDoG-atc1.0-tau0.5'
Process 0 using device: cuda
-> state initialization complete 

=> enable xformers
Diffusion Model: Nihirc/Prompt2MedImage
DDIMScheduler {
  "_class_name": "DDIMScheduler",
  "_diffusers_version": "0.20.2",
  "beta_end": 0.012,
  "beta_schedule": "scaled_linear",
  "beta_start": 0.00085,
  "clip_sample": false,
  "clip_sample_range": 1.0,
  "dynamic_thresholding_ratio": 0.995,
  "num_train_timesteps": 1000,
  "prediction_type": "epsilon",
  "rescale_betas_zero_snr": false,
  "sample_max_value": 1.0,
  "set_alpha_to_one": false,
  "skip_prk_steps": true,
  "steps_offset": 1,
  "thresholding": false,
  "timestep_spacing": "leading",
  "trained_betas": null
}

prompt: A brain PET-MRI axial image with huge tumors
negative_prompt: None

the length of tokens is 12, select 4-th token
origin cross_attn_map shape: torch.Size([16, 16, 77])
select cross_attn_map shape: torch.Size([16, 16])

self-attention_maps: (1024, 1024), u: (1024, 1024), s: (1024,), vh: (1024, 1024)
select 0-th comp.
-> fusion attn_map: (224, 224)
the length of tokens is 12, select 4-th token
origin cross_attn_map shape: torch.Size([16, 16, 77])
select cross_attn_map shape: torch.Size([16, 16])

self-attention_maps: (1024, 1024), u: (1024, 1024), s: (1024,), vh: (1024, 1024)
select 0-th comp.
-> fusion attn_map: (224, 224)
the length of tokens is 12, select 4-th token
origin cross_attn_map shape: torch.Size([16, 16, 77])
select cross_attn_map shape: torch.Size([16, 16])

self-attention_maps: (1024, 1024), u: (1024, 1024), s: (1024,), vh: (1024, 1024)
select 0-th comp.
-> fusion attn_map: (224, 224)
the length of tokens is 12, select 4-th token
origin cross_attn_map shape: torch.Size([16, 16, 77])
select cross_attn_map shape: torch.Size([16, 16])

self-attention_maps: (1024, 1024), u: (1024, 1024), s: (1024,), vh: (1024, 1024)
select 0-th comp.
-> fusion attn_map: (224, 224)
100 denoising steps, [991, 981, 971, 961, 951, 941, 931, 921, 911, 901, 891, 881, 871, 861, 851, 841, 831, 821, 811, 801, 791, 781, 771, 761, 751, 741, 731, 721, 711, 701, 691, 681, 671, 661, 651, 641, 631, 621, 611, 601, 591, 581, 571, 561, 551, 541, 531, 521, 511, 501, 491, 481, 471, 461, 451, 441, 431, 421, 411, 401, 391, 381, 371, 361, 351, 341, 331, 321, 311, 301, 291, 281, 271, 261, 251, 241, 231, 221, 211, 201, 191, 181, 171, 161, 151, 141, 131, 121, 111, 101, 91, 81, 71, 61, 51, 41, 31, 21, 11, 1]
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/hbc/DS/DiffSketcher/libs/metric/lpips_origin/weights/v0.1/vgg.pth
inputs shape:  torch.Size([1, 3, 224, 224])
Using cached ./models
use XDoG, shape: (224, 224)
use XDoG, shape: (224, 224)
use XDoG, shape: (224, 224)
use XDoG, shape: (224, 224)
init_image shape:  torch.Size([1, 3, 224, 224])
-> Painter points Params: 1200
-> Painter width Params: 0
-> Painter opacity Params: 1200

total optimization steps: 500

GPU memory usage: 8.72 GB
painterly rendering complete.
